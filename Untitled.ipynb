{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93a20b8-579c-4d77-a838-641c05087ebb",
   "metadata": {},
   "source": [
    "#### import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from tabulate import tabulate\n",
    "from skimage import exposure\n",
    "\n",
    "# ===== PREPROCESSING FUNCTIONS =====\n",
    "def apply_clahe(gray_image, clip_limit=2.0, tile_size=8):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(tile_size, tile_size))\n",
    "    return clahe.apply(gray_image)\n",
    "\n",
    "def gaussian_blur_canny(image, kernel_size=5, canny_low=50, canny_high=150, use_clahe=True):\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    if use_clahe:\n",
    "        gray = apply_clahe(gray)\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
    "    edges = cv2.Canny(blurred, canny_low, canny_high)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def extract_shape_boundaries(image, kernel_size=5, min_area=100):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    result = np.zeros_like(image)\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area: \n",
    "            cv2.drawContours(result, [contour], -1, 255, 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def extract_inner_region(original_image, boundary_image):\n",
    "    mask = boundary_image.copy()\n",
    "    contours, _ = cv2.findContours(boundary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        cv2.fillPoly(mask, [contour], 255)\n",
    "    \n",
    "    mask_normalized = mask.astype(np.float32) / 255.0\n",
    "    \n",
    "    if len(original_image.shape) == 3:  \n",
    "        result = original_image.copy().astype(np.float32)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = result[:, :, i] * mask_normalized\n",
    "        result = result.astype(np.uint8)\n",
    "    else: \n",
    "        result = (original_image.astype(np.float32) * mask_normalized).astype(np.uint8)\n",
    "    \n",
    "    return result, mask\n",
    "\n",
    "def extract_inner_region_cropped(original_image, boundary_image):\n",
    "    inner_image, mask = extract_inner_region(original_image, boundary_image)\n",
    "    contours, _ = cv2.findContours(boundary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) > 0:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cropped = inner_image[y:y+h, x:x+w]\n",
    "        return cropped, (x, y, w, h)\n",
    "    \n",
    "    return inner_image, None\n",
    "\n",
    "def resize_image(image, target_size=512):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = min(target_size / h, target_size / w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    if len(resized.shape) == 3:\n",
    "        canvas = np.zeros((target_size, target_size, resized.shape[2]), dtype=resized.dtype)\n",
    "    else:\n",
    "        canvas = np.zeros((target_size, target_size), dtype=resized.dtype)\n",
    "    \n",
    "    y_offset = (target_size - new_h) // 2\n",
    "    x_offset = (target_size - new_w) // 2\n",
    "    \n",
    "    if len(resized.shape) == 3:\n",
    "        canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w, :] = resized\n",
    "    else:\n",
    "        canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "    \n",
    "    return canvas\n",
    "\n",
    "def structural_similarity_score(test_image, train_image):\n",
    "    \"\"\"\n",
    "    Calculate structural similarity using multiple metrics\n",
    "    \"\"\"\n",
    "    if len(test_image.shape) == 3:\n",
    "        test_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        test_gray = test_image.copy()\n",
    "    \n",
    "    if len(train_image.shape) == 3:\n",
    "        train_gray = cv2.cvtColor(train_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        train_gray = train_image.copy()\n",
    "    \n",
    "   \n",
    "    test_gray = apply_clahe(test_gray, clip_limit=3.0, tile_size=8)\n",
    "    train_gray = apply_clahe(train_gray, clip_limit=3.0, tile_size=8)\n",
    "    \n",
    "    test_gray = cv2.bilateralFilter(test_gray, 11, 80, 80)\n",
    "    train_gray = cv2.bilateralFilter(train_gray, 11, 80, 80)\n",
    "    \n",
    "    test_edges = cv2.Canny(test_gray, 50, 150)\n",
    "    train_edges = cv2.Canny(train_gray, 50, 150)\n",
    "    \n",
    "    test_edges_norm = test_edges.astype(np.float32) / 255.0\n",
    "    train_edges_norm = train_edges.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Calculate edge overlap\n",
    "    edge_intersection = np.sum(test_edges_norm * train_edges_norm)\n",
    "    edge_union = np.sum(np.maximum(test_edges_norm, train_edges_norm))\n",
    "    edge_similarity = edge_intersection / (edge_union + 1e-10)\n",
    "    \n",
    "    # 2. Normalized cross-correlation on grayscale\n",
    "    test_norm = (test_gray - np.mean(test_gray)) / (np.std(test_gray) + 1e-10)\n",
    "    train_norm = (train_gray - np.mean(train_gray)) / (np.std(train_gray) + 1e-10)\n",
    "    ncc = np.sum(test_norm * train_norm) / (test_norm.size)\n",
    "    ncc_score = (ncc + 1) / 2  \n",
    "    \n",
    "    combined = 0.7 * edge_similarity + 0.3 * ncc_score\n",
    "    return combined\n",
    "\n",
    "def match_histograms(source, reference):\n",
    "\n",
    "    if len(source.shape) == 3:\n",
    "        source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        source_gray = source.copy()\n",
    "    \n",
    "    if len(reference.shape) == 3:\n",
    "        reference_gray = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        reference_gray = reference.copy()\n",
    "    \n",
    "    matched = exposure.match_histograms(source_gray, reference_gray, channel_axis=None)\n",
    "    matched = np.uint8(matched)\n",
    "    \n",
    "    return matched\n",
    "\n",
    "\n",
    "# ===== TEMPLATE MATCHING =====\n",
    "def prepare_matching_image(image, method='clahe_hist'):\n",
    "    \"\"\"Prepare image for template matching\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    gray = np.clip(gray.astype(np.float32), 0, 255).astype(np.uint8)\n",
    "    \n",
    "    if method == 'clahe_hist':\n",
    "        gray = apply_clahe(gray, clip_limit=2.0, tile_size=8)\n",
    "        gray = cv2.equalizeHist(gray)\n",
    "        gray = np.clip(gray.astype(np.float32), 0, 255).astype(np.uint8)\n",
    "        return gray\n",
    "    \n",
    "    elif method == 'edge':\n",
    "        # Edge detection for structural matching\n",
    "        gray = apply_clahe(gray, clip_limit=3.0, tile_size=8)\n",
    "        gray = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 30, 100)\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "        return edges\n",
    "    \n",
    "\n",
    "def template_match(test_image, training_image, method=cv2.TM_CCOEFF_NORMED, prep_method='clahe_hist', use_histogram_matching=False):\n",
    "    \"\"\"\n",
    "    Template matching with improved preprocessing\n",
    "    use_histogram_matching: If True, matches test image histogram to training image before preprocessing\n",
    "    \"\"\"\n",
    "    # Apply histogram matching first if enabled\n",
    "    if use_histogram_matching:\n",
    "        test_image = match_histograms(test_image, training_image)\n",
    "    \n",
    "    test_gray = prepare_matching_image(test_image, method=prep_method)\n",
    "    train_gray = prepare_matching_image(training_image, method=prep_method)\n",
    "    \n",
    "    if test_image.shape[0] > training_image.shape[0] or test_image.shape[1] > training_image.shape[1]:\n",
    "        test_image, training_image = training_image, test_image\n",
    "    \n",
    "    result = cv2.matchTemplate(training_image, test_image, method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    \n",
    "    return max_val, test_gray, train_gray\n",
    "\n",
    "def process_image_pipeline(image_path, plot_intermediate=False, title=\"\", min_area=500, target_size=512):\n",
    "    \"\"\"Complete pipeline: read -> resize -> detect edges -> extract region -> crop\"\"\"\n",
    "    img = cv2.imread(image_path, 1)\n",
    "    img = resize_image(img, target_size=target_size)\n",
    "    edges = gaussian_blur_canny(img)\n",
    "    boundaries = extract_shape_boundaries(edges, min_area=min_area)\n",
    "    cropped_region, bbox = extract_inner_region_cropped(img, boundaries)\n",
    "    \n",
    "    if cropped_region is None:\n",
    "        inner_region, mask = extract_inner_region(img, boundaries)\n",
    "        cropped_region = inner_region\n",
    "    \n",
    "    cropped_region = resize_image(cropped_region, target_size=target_size)\n",
    "    \n",
    "    if plot_intermediate:\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = img.copy()\n",
    "        \n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        fig.suptitle(f'Processing Pipeline: {title}', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0, 0].set_title('Original (Resized 512x512)')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        axes[0, 1].imshow(gray, cmap='gray')\n",
    "        axes[0, 1].set_title('Grayscale')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        axes[0, 2].imshow(blurred, cmap='gray')\n",
    "        axes[0, 2].set_title('Gaussian Blur')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        axes[0, 3].imshow(edges, cmap='gray')\n",
    "        axes[0, 3].set_title('Canny Edges')\n",
    "        axes[0, 3].axis('off')\n",
    "        \n",
    "        axes[1, 0].imshow(boundaries, cmap='gray')\n",
    "        axes[1, 0].set_title('Shape Boundaries')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        inner_region, mask = extract_inner_region(img, boundaries)\n",
    "        axes[1, 1].imshow(cv2.cvtColor(inner_region, cv2.COLOR_BGR2RGB))\n",
    "        axes[1, 1].set_title('Inner Region')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        if len(cropped_region.shape) == 3:\n",
    "            axes[1, 2].imshow(cv2.cvtColor(cropped_region, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            axes[1, 2].imshow(cropped_region, cmap='gray')\n",
    "        axes[1, 2].set_title('Cropped & Resized (512x512)')\n",
    "        axes[1, 2].axis('off')\n",
    "        \n",
    "        axes[1, 3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return cropped_region\n",
    "\n",
    "def plot_matching_images(test_name, test_gray, train_names, train_grays, scores, normalized_scores, best_idx, prep_method, use_hist_match):\n",
    "    n_trains = len(train_names)\n",
    "    fig, axes = plt.subplots(2, n_trains + 1, figsize=(4 * (n_trains + 1), 8))\n",
    "    \n",
    "    method_names = {\n",
    "        'clahe_hist': 'CLAHE + Histogram Equalization',\n",
    "        'edge': 'Edge Detection (Canny)',\n",
    "    }\n",
    "    \n",
    "    hist_match_str = \" + Histogram Matching\" if use_hist_match else \"\"\n",
    "    fig.suptitle(f'Template Matching Images for Test: {test_name}\\nPreprocessing: {method_names.get(prep_method, prep_method)}{hist_match_str}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # First column: Test image\n",
    "    axes[0, 0].imshow(test_gray, cmap='gray')\n",
    "    axes[0, 0].set_title(f'Test: {test_name}\\n(After Preprocessing)', fontweight='bold', fontsize=11)\n",
    "    axes[0, 0].axis('off')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Remaining columns: Training images with scores\n",
    "    for i, (name, train_gray, score, norm_score) in enumerate(zip(train_names, train_grays, scores, normalized_scores)):\n",
    "        col = i + 1\n",
    "        \n",
    "        # Top row: Training image\n",
    "        axes[0, col].imshow(train_gray, cmap='gray')\n",
    "        title_color = 'green' if i == best_idx else 'black'\n",
    "        axes[0, col].set_title(f'Train: {name}\\n(After Preprocessing)', \n",
    "                               fontweight='bold' if i == best_idx else 'normal',\n",
    "                               color=title_color, fontsize=11)\n",
    "        axes[0, col].axis('off')\n",
    "        \n",
    "        # Bottom row: Score with percentage\n",
    "        score_text = f'Score: {score:.4f}\\n({norm_score:.1f}%)'\n",
    "        axes[1, col].text(0.5, 0.5, score_text, \n",
    "                         ha='center', va='center', fontsize=12, fontweight='bold',\n",
    "                         color=title_color,\n",
    "                         transform=axes[1, col].transAxes)\n",
    "        axes[1, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_score_comparison(test_name, training_names, scores, normalized_scores, best_idx, threshold, prep_method, use_hist_match):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    \n",
    "    hist_match_str = \" + Histogram Matching\" if use_hist_match else \"\"\n",
    "    fig.suptitle(f'Template Matching Scores for Test: {test_name}\\nPreprocessing: {prep_method}{hist_match_str}', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Left plot: Raw scores\n",
    "    colors = ['green' if i == best_idx else 'steelblue' for i in range(len(scores))]\n",
    "    bars1 = ax1.bar(training_names, scores, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax1.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold})')\n",
    "    \n",
    "    for bar, score in zip(bars1, scores):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{score:.4f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax1.set_ylabel('Average Score', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Training Classes', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Raw Scores (Average across variants)', fontsize=12, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    ax1.set_ylim([0, max(scores) * 1.2])\n",
    "    \n",
    "    # Right plot: Normalized percentages\n",
    "    bars2 = ax2.bar(training_names, normalized_scores, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, norm_score in zip(bars2, normalized_scores):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{norm_score:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax2.set_ylabel('Normalized Score (%)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('Training Classes', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Normalized Scores (Sum = 100%)', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    ax2.set_ylim([0, 100])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ===== MAIN WORKFLOW =====\n",
    "\n",
    "# Step 1: Define training images dictionary - MULTIPLE IMAGES PER CLASS\n",
    "training_images = {\n",
    "    'stop': ['train/stop.jpg', 'train/stop_2.png', 'train/stop_3.jpg'],\n",
    "    'limit1': ['train/limit1.jpg', 'train/limit1_2.jpg', 'train/limit1_3.jpg'],\n",
    "    'limit2': ['train/limit2.png', 'train/limit2_2.jpg', 'train/limit2_3.jpg'],\n",
    "    'limit3': ['train/limit3.jpg', 'train/limit3_2.jpg', 'train/limit3_3.jpg'],\n",
    "    'no_parking': ['train/nop.png', 'train/nop_2.jpg', 'train/nop_3.jpg'],\n",
    "    'pedestrain': ['train/pedes.png', 'train/pedes_2.jpg', 'train/pedes_3.jpg'],\n",
    "    'caution': ['train/caution.jpg', 'train/caution_2.jpg', 'train/caution_3.jpg'],\n",
    "}\n",
    "\n",
    "# Step 2: Process training images (now handles multiple images per class)\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING PHASE: Processing training images...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "training_images_processed = {}\n",
    "training_names = list(training_images.keys())\n",
    "\n",
    "for name, paths in training_images.items():\n",
    "    processed_variants = []\n",
    "    print(f\"\\nProcessing class: {name}\")\n",
    "    \n",
    "    for idx, path in enumerate(paths, 1):\n",
    "        try:\n",
    "            cropped = process_image_pipeline(path, plot_intermediate=True, \n",
    "                                            title=f\"Training: {name} (variant {idx})\")\n",
    "            processed_variants.append(cropped)\n",
    "            print(f\" Processed: {name} - variant {idx}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {name} variant {idx}: {e}\")\n",
    "            # Continue even if one variant fails\n",
    "    \n",
    "    if processed_variants:\n",
    "        training_images_processed[name] = processed_variants\n",
    "        print(f\" Class {name}: {len(processed_variants)} variants processed\")\n",
    "    else:\n",
    "        print(f\" Class {name}: No variants successfully processed!\")\n",
    "\n",
    "# Step 3: Define test images dictionary\n",
    "test_images = {\n",
    "    'test': 'train/limit2_2.jpg',\n",
    "}\n",
    "\n",
    "# Step 4: Process test images and compare with TEMPLATE MATCHING\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING PHASE: Template Matching...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "PREPROCESSING_METHOD = 'edge'  \n",
    "USE_HISTOGRAM_MATCHING = True  \n",
    "USE_STRUCTURAL_SIMILARITY = False  \n",
    "THRESHOLD = 0.15  \n",
    "\n",
    "results_table = []\n",
    "matching_results = []\n",
    "\n",
    "for test_name, test_path in test_images.items():\n",
    "    try:\n",
    "        test_cropped = process_image_pipeline(\n",
    "            test_path, plot_intermediate=True, title=f\"Test: {test_name}\"\n",
    "        )\n",
    "        \n",
    "# Calculate template matching scores with all training images\n",
    "        scores = []\n",
    "        train_grays = []\n",
    "        best_variant_indices = []\n",
    "        test_gray = None\n",
    "        \n",
    "        print(f\"Template matching {test_name} against training images:\")\n",
    "        for train_name, train_image_variants in training_images_processed.items():\n",
    "            best_score_for_class = 0\n",
    "            best_gray_for_class = None\n",
    "            best_variant_idx = 0\n",
    "            \n",
    "            # Compare against each variant and keep the best score\n",
    "            for variant_idx, train_variant in enumerate(train_image_variants):\n",
    "                if USE_STRUCTURAL_SIMILARITY:\n",
    "                    # Use improved structural similarity\n",
    "                    score = structural_similarity_score(test_cropped, train_variant)\n",
    "                else:\n",
    "                    # Use original template matching\n",
    "                    score, _, _ = template_match(test_cropped, train_variant, \n",
    "                                                prep_method=PREPROCESSING_METHOD,\n",
    "                                                use_histogram_matching=USE_HISTOGRAM_MATCHING)\n",
    "                \n",
    "                # Keep track of best variant for this class\n",
    "                if score > best_score_for_class:\n",
    "                    best_score_for_class = score\n",
    "                    best_variant_idx = variant_idx\n",
    "            \n",
    "            # Now get the preprocessed images for the best variant\n",
    "            best_variant = train_image_variants[best_variant_idx]\n",
    "            if USE_STRUCTURAL_SIMILARITY:\n",
    "                _, t_gray, tr_gray = template_match(test_cropped, best_variant, \n",
    "                                                    prep_method=PREPROCESSING_METHOD,\n",
    "                                                    use_histogram_matching=USE_HISTOGRAM_MATCHING)\n",
    "            else:\n",
    "                _, t_gray, tr_gray = template_match(test_cropped, best_variant, \n",
    "                                                    prep_method=PREPROCESSING_METHOD,\n",
    "                                                    use_histogram_matching=USE_HISTOGRAM_MATCHING)\n",
    "            \n",
    "            scores.append(best_score_for_class)\n",
    "            train_grays.append(tr_gray)\n",
    "            best_variant_indices.append(best_variant_idx)\n",
    "            \n",
    "            if test_gray is None:\n",
    "                test_gray = t_gray\n",
    "            \n",
    "            print(f\"  {train_name}: {best_score_for_class:.4f} (variant {best_variant_idx + 1})\")\n",
    "        \n",
    "        # Normalize scores to percentages (sum to 100%)\n",
    "        scores_array = np.array(scores)\n",
    "        if scores_array.sum() > 0:\n",
    "            normalized_scores = (scores_array / scores_array.sum()) * 100\n",
    "        else:\n",
    "            normalized_scores = np.zeros_like(scores_array)\n",
    "        \n",
    "        best_idx = np.argmax(normalized_scores)  # Best based on normalized scores\n",
    "        best_score = scores[best_idx]\n",
    "        best_normalized_score = normalized_scores[best_idx]\n",
    "        best_class = training_names[best_idx]\n",
    "        best_variant = best_variant_indices[best_idx]\n",
    "        is_match = best_score > THRESHOLD\n",
    "        \n",
    "        # Plot the preprocessed images used for matching\n",
    "        print(f\"Showing best matching variants for each class...\")\n",
    "        plot_matching_images(test_name, test_gray, training_names, train_grays, \n",
    "                           scores, normalized_scores, best_idx, PREPROCESSING_METHOD, USE_HISTOGRAM_MATCHING)\n",
    "        \n",
    "        # Plot score comparison bar chart\n",
    "        plot_score_comparison(test_name, training_names, scores, normalized_scores, best_idx, \n",
    "                            THRESHOLD, PREPROCESSING_METHOD, USE_HISTOGRAM_MATCHING)\n",
    "        \n",
    "        # Create table row\n",
    "        row = [test_name]\n",
    "        for score, norm_score in zip(scores, normalized_scores):\n",
    "            row.append(f'{score:.4f}\\n({norm_score:.1f}%)')\n",
    "        \n",
    "        if is_match:\n",
    "            matched_label = f\"{best_class}\\n({best_normalized_score:.1f}%)\"\n",
    "            result = f\" {test_name} => {best_class} ({best_normalized_score:.1f}%, score: {best_score:.4f})\"\n",
    "            row.append(matched_label)\n",
    "        else:\n",
    "            result = f\" {test_name} => NO MATCH (best: {best_class} {best_normalized_score:.1f}%, score: {best_score:.4f})\"\n",
    "            row.append(\"NO MATCH\")\n",
    "        \n",
    "        results_table.append(row)\n",
    "        matching_results.append({\n",
    "            'test_name': test_name,\n",
    "            'matched': is_match,\n",
    "            'match_class': best_class if is_match else \"Unknown\",\n",
    "            'normalized_score': best_normalized_score,\n",
    "            'raw_score': best_score\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{result}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error processing test image {test_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Step 5: Display results table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEMPLATE MATCHING SCORES\")\n",
    "print(\"=\" * 60)\n",
    "headers = ['Test Image'] + training_names + ['Match Result']\n",
    "print(tabulate(results_table, headers=headers, tablefmt='grid'))\n",
    "\n",
    "# Step 6: Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MATCHING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Method: {'Structural Similarity' if USE_STRUCTURAL_SIMILARITY else 'Template Matching'}\")\n",
    "print(f\"Preprocessing: {PREPROCESSING_METHOD}\")\n",
    "print(f\"Histogram Matching: {'ENABLED' if USE_HISTOGRAM_MATCHING else 'DISABLED'}\")\n",
    "print(f\"Threshold: {THRESHOLD}\")\n",
    "print(f\"Total Tests: {len(matching_results)}\")\n",
    "matches_found = sum(1 for r in matching_results if r['matched'])\n",
    "print(f\"Matches Found: {matches_found}\")\n",
    "print(f\"No Match: {len(matching_results) - matches_found}\")\n",
    "print()\n",
    "\n",
    "for result in matching_results:\n",
    "    status = \"✓ MATCH\" if result['matched'] else \"✗ NO MATCH\"\n",
    "    print(f\"  {status} | {result['test_name']} => {result['match_class']} ({result['normalized_score']:.1f}%, raw: {result['raw_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b3891-cf88-499b-bf31-e871ad53b79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
